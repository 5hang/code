docker 安装 zookeeper

docker-compose.yml 

version: "3.1"
services:
 zk:
  image: daocloud.io/daocloud/zookeeper:latest
  restart: always
  container_name: zk
  ports:
   - 2181:2181
docker-compose up -d    到这里成功安装并启动zookeeper

docker exec -it zk bash
cd bin
./zkCli.sh


下载 kafka
wget https://archive.apache.org/dist/kafka/2.4.1/kafka_2.11-2.4.1.tgz

解压kafka
config/server.properies 配置

#kafka集群中的唯一id
broker.id=0
#kafka 部署的服务的提供服务的IP端口
listeners=PLAINTEXT://192.168.13.134:9092
#kafka日志路径
log.dir=/tmp/kafka-logs
#kafka 链接 zookeeper的地址
zookeeper.connect=192.168.13.134:2181

启动kafka
[root@xxx bin]# ./kafka-server-start.sh -daemon ../config/server.properties 
查看是否启动成功了



************************************kafka中的概念************************

创建topic
./kafka-topics.sh --create --zookeeper 192.168.13.134:2181 --replication-factor 1 --partitions 1 --topic test

查看topic
./kafka-topics.sh  --list --zookeeper  192.168.13.134:2181

发送消息
./kafka-console-producer.sh --broker-list 192.168.13.134:9092  --topic test


消费消息
1:  从最后一条偏移量+1开始消费
 ./kafka-console-consumer.sh --bootstrap-server 192.168.13.134:9092 --topic test

2： 从头开始消费
./kafka-console-consumer.sh --bootstrap-server  192.168.13.134:9092 --from-beginning --topic test

 
 上面的发送 消费消息，多个人消费，一个人发送 ，接收方每个人都可以收到消息的
 
 单播消息
./kafka-console-consumer.sh --bootstrap-server 192.168.13.134:9092 --consumer-property group.id=testGroup --topic test
 
 多播消息
 --consumer-property group.id=testGroup
 同一个消费组中只有一个消费组能获取消息
 不同消费组的  2个都能获取消息的
 
**生产者将消息发送到broker ，broker将消息保存在本地日志文件中
/var/kafka-log 
消息的保存是有顺序的，
消费者可以通过offset来读取指定位置的消息



  private final static String TOPIC_NAME =  "my-replicated-topic";
    private final static String CONSUMER_GROUP_NAME = "testGroup";

    public static void main(String[] args){
        Properties props = new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "192.168.13.134:9092,192.168.13.134:9093,192.168.13.134:9094");

        // 消费主题另一个新的消费组  进行消费了  latest：默认 只消费自己启动后消费都的位置
        // earliest：第一次从头开始消费，以后按照offset记录进行消费的
        // 当设置earliest时候只有再第一次的时候从头开始  以后就接着offset消费了
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG,"latest");

        // 默认 配置长轮询时间1秒  每次pull 500条记录
        // 如果pull到了500条，立即返回，如果不够500条 就等到 500条 或者1s
        props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG,500);
        // 如果2次pull的时间检测超过30秒，broker就会认为这个消费者 消费能力不够，会把他提出消费组，触发 rebalance 可以将500改成100
        props.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG,30*1000);
        // 消费者的健康检查， 消费者每1s 向broker发送心跳包，超过10s没有发送心跳，
        // 就会认为这个消费者 挂了 ，把他提出消费组
        props.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG,1000);
        props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG,10*1000);

        //offset  设置是否自动提交   默认true
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG,"false");
        // 自动提交是 pull后还未消费的时候 就提交（如果此时 消费者挂了  那么消息就会丢失了）
        // 手动提交是 pull后 并且消费了消息 再提交
        // 自动提交的间隔时间是多少呢
        props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG,"1000");

        props.put(ConsumerConfig.GROUP_ID_CONFIG,CONSUMER_GROUP_NAME);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class.getName());

        KafkaConsumer<String, String>consumer = new KafkaConsumer<String, String>(props);

        consumer.subscribe(Arrays.asList(TOPIC_NAME));
        //消费指定的分区
//        consumer.assign(Arrays.asList(new TopicPartition(TOPIC_NAME,0)));
// 回溯消费，从offset 0开始的所有消息进行消费
//        consumer.seekToBeginning(Arrays.asList(new TopicPartition(TOPIC_NAME,0)));

// 指定offset进行消费
//        consumer.seek(new TopicPartition(TOPIC_NAME,0),10);

        while (true){

            ConsumerRecords<String , String>  records = consumer.poll(Duration.ofMillis(1000));

            for(ConsumerRecord<String, String>record:records){
System.out.printf("收到消息:patririon = %d, offset = %d ,key = %s, value = %s%n", record.partition(),record.offset(),record.key(),record.value());
            }


            if(records.count()>0){

                //消费结束后 手动提交，手动提交 ，分为 同步 提交  异步提交2种奥
                // 这个过程是阻塞的  只到返回 ack  一般同步提交的
                consumer.commitSync();

                // 异步提交了
//                consumer.commitAsync(new OffsetCommitCallback() {
//                    @Override
//                    public void onComplete(Map<TopicPartition, OffsetAndMetadata> map, Exception e) {
//                        if(e != null){
//
//                        }
//                    }
//                });
            }
        }









